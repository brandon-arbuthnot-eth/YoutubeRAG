{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "YOUTUBE_URL = \"https://www.youtube.com/watch?v=9UxAUryUKXM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "model = ChatAnthropic(model='claude-3-sonnet-20240229')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "template = \"\"\" Answer the question succinctly using the context. If You can't answer the question, reply \"I don't know\". Context: {context} Question: {question} \"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading audio...\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=9UxAUryUKXM\n",
      "[youtube] 9UxAUryUKXM: Downloading webpage\n",
      "[youtube] 9UxAUryUKXM: Downloading ios player API JSON\n",
      "[youtube] 9UxAUryUKXM: Downloading tv player API JSON\n",
      "[youtube] 9UxAUryUKXM: Downloading m3u8 information\n",
      "[info] 9UxAUryUKXM: Downloading 1 format(s): 251\n",
      "[download] 9UxAUryUKXM.webm has already been downloaded\n",
      "[download] 100% of   42.52MiBDownloading: 100.0%\n",
      "\n",
      "Loading Whisper model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brand\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\whisper\\__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing audio...\n",
      "Transcription took 276.65 seconds\n",
      "Transcription complete. Results saved in 'transcription.txt'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import whisper\n",
    "import yt_dlp\n",
    "import time\n",
    "\n",
    "def download_audio(url):\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'postprocessors': [],\n",
    "        'outtmpl': '%(id)s.%(ext)s',\n",
    "        'progress_hooks': [lambda d: print(f'Downloading: {d[\"_percent_str\"]}')]\n",
    "    }\n",
    "    \n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        info = ydl.extract_info(url, download=True)\n",
    "        return ydl.prepare_filename(info)\n",
    "\n",
    "def transcribe_audio(filename):\n",
    "    print(\"Loading Whisper model...\")\n",
    "    model = whisper.load_model(\"tiny\")\n",
    "    print(\"Transcribing audio...\")\n",
    "    start_time = time.time()\n",
    "    result = model.transcribe(filename, fp16=False)\n",
    "    end_time = time.time()\n",
    "    print(f\"Transcription took {end_time - start_time:.2f} seconds\")\n",
    "    return result[\"text\"].strip()\n",
    "\n",
    "if not os.path.exists(\"transcription.txt\"):\n",
    "    YOUTUBE_URL = \"https://www.youtube.com/watch?v=9UxAUryUKXM\"  # Replace with your YouTube URL\n",
    "    \n",
    "    print(\"Downloading audio...\")\n",
    "    filename = download_audio(YOUTUBE_URL)\n",
    "    \n",
    "    transcription = transcribe_audio(filename)\n",
    "    \n",
    "    with open(\"transcription.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(transcription)\n",
    "    \n",
    "    os.remove(filename)\n",
    "\n",
    "print(\"Transcription complete. Results saved in 'transcription.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"transcription.txt\", encoding=\"utf-8\")\n",
    "text_documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "documents = text_splitter.split_documents(text_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brand\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "index_name = \"youtube-rag-index\"\n",
    "\n",
    "pinecone = PineconeVectorStore.from_documents(\n",
    "    documents, embeddings, index_name=index_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_context = RunnableParallel(context=pinecone.as_retriever(), question=RunnablePassthrough())\n",
    "chain = setup_context | prompt | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No, the speaker does not mention buying more Bitcoin at all in the given context.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Does the speaker mention buying more Bitcoin at all?\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "13b4de4f70e60507ad06be42991e447cda39e5a0e737a8e74eeff279970a81d5"
  },
  "kernelspec": {
   "display_name": "Python 3.12.3 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
